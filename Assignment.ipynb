{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ocf_dPrJP6u5",
        "outputId": "d301840f-4a9a-44db-900a-53ce6cd75ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2061631315.py:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  return df.groupby(\"target\", group_keys=False).apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling  BOOTSTRAP  CLUSTER  RANDOM  STRATIFIED  SYSTEMATIC\n",
            "Algo                                                        \n",
            "DT           100.00    97.40   99.46       96.74       98.69\n",
            "LR            93.46    89.61   93.48       94.02       89.54\n",
            "NB            70.59    68.83   76.63       76.63       73.86\n",
            "RF           100.00   100.00  100.00      100.00      100.00\n",
            "SVM           98.37    98.70   98.91       97.83       98.04\n",
            "\n",
            "Best Sampling Per Model\n",
            "\n",
            "Algo\n",
            "DT      BOOTSTRAP\n",
            "LR     STRATIFIED\n",
            "NB         RANDOM\n",
            "RF      BOOTSTRAP\n",
            "SVM        RANDOM\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"Creditcard_data.csv\")\n",
        "\n",
        "A = dataset.drop(\"Class\", axis=1)\n",
        "B = dataset[\"Class\"]\n",
        "\n",
        "balancer = RandomOverSampler(random_state=21)\n",
        "A_res, B_res = balancer.fit_resample(A, B)\n",
        "\n",
        "merged = pd.DataFrame(A_res, columns=A.columns)\n",
        "merged[\"target\"] = B_res\n",
        "\n",
        "\n",
        "def rnd_sample(df, portion=0.6):\n",
        "    return df.sample(frac=portion, random_state=21)\n",
        "\n",
        "def sys_sample(df, gap=2):\n",
        "    return df.iloc[::gap]\n",
        "\n",
        "def strat_sample(df, portion=0.6):\n",
        "    return df.groupby(\"target\", group_keys=False).apply(\n",
        "        lambda d: d.sample(frac=portion, random_state=21)\n",
        "    )\n",
        "\n",
        "def clust_sample(df, parts=4):\n",
        "    temp = df.copy()\n",
        "    temp[\"grp\"] = temp.index % parts\n",
        "    pick = np.random.choice(temp[\"grp\"].unique())\n",
        "    return temp[temp[\"grp\"] == pick].drop(\"grp\", axis=1)\n",
        "\n",
        "def boot_sample(df):\n",
        "    return df.sample(n=len(df), replace=True, random_state=21)\n",
        "\n",
        "\n",
        "data_variants = {\n",
        "    \"RANDOM\": rnd_sample(merged),\n",
        "    \"SYSTEMATIC\": sys_sample(merged),\n",
        "    \"STRATIFIED\": strat_sample(merged),\n",
        "    \"CLUSTER\": clust_sample(merged),\n",
        "    \"BOOTSTRAP\": boot_sample(merged)\n",
        "}\n",
        "\n",
        "\n",
        "algo_bank = {\n",
        "    \"LR\": LogisticRegression(max_iter=1200),\n",
        "    \"DT\": DecisionTreeClassifier(random_state=21),\n",
        "    \"RF\": RandomForestClassifier(n_estimators=120, random_state=21),\n",
        "    \"NB\": GaussianNB(),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "\n",
        "scores = []\n",
        "\n",
        "for tag, block in data_variants.items():\n",
        "    Xv = block.drop(\"target\", axis=1)\n",
        "    yv = block[\"target\"]\n",
        "\n",
        "    normalizer = StandardScaler()\n",
        "    Xn = normalizer.fit_transform(Xv)\n",
        "\n",
        "    Xtr, Xts, ytr, yts = train_test_split(\n",
        "        Xn, yv, test_size=0.2, random_state=21, stratify=yv\n",
        "    )\n",
        "\n",
        "    for name, algo in algo_bank.items():\n",
        "        algo.fit(Xtr, ytr)\n",
        "        out = algo.predict(Xts)\n",
        "\n",
        "        scores.append({\n",
        "            \"Algo\": name,\n",
        "            \"Sampling\": tag,\n",
        "            \"Score\": accuracy_score(yts, out) * 100\n",
        "        })\n",
        "\n",
        "\n",
        "table = pd.DataFrame(scores)\n",
        "\n",
        "final_view = (\n",
        "    table\n",
        "    .pivot(index=\"Algo\", columns=\"Sampling\", values=\"Score\")\n",
        "    .round(2)\n",
        ")\n",
        "\n",
        "print(final_view)\n",
        "print(\"\\nBest Sampling Per Model\\n\")\n",
        "print(final_view.idxmax(axis=1))\n"
      ]
    }
  ]
}